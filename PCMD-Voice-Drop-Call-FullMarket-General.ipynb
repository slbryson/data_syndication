{
 "metadata": {
  "name": "",
  "signature": "sha256:09754bde8f46a1a79297bfed228d456045314aa47b2cde6fda6de6119dd30473"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import csv\n",
      "\n",
      "maxReadRows = 1000000\n",
      "inputFile = r'\\Boston_CDMA.csv'\n",
      "inputFile = r'\\LA_Metro_CDMA_drop_call_analysis.csv'\n",
      "\n",
      "lst_myFieldNames = ['ECP', 'Cell', 'Sector', 'Carrier', 'Date', 'Hour', \n",
      "                   'Dropped Call Timestamp', 'Call Final Class qualifier', \n",
      "                   'Secondary Call Final Class qualifier', 'Analysis Type', \n",
      "                   'Analysis Reason', 'Mobile Vendor', 'Mobile serial number', \n",
      "                   'Ending Band Class', 'Average FL Power (Watts)', \n",
      "                   'Average RL RSSI rise (dB)']\n",
      "lst_Rows = []\n",
      "lst_myFieldNumbers = []\n",
      "rowCount = 0\n",
      "with open(inputFile) as csvFile:\n",
      "    csvReader = csv.reader(csvFile, dialect = 'excel')\n",
      "    firstLine = next(csvReader)\n",
      "    i = 0\n",
      "    for field in firstLine:\n",
      "        if field in lst_myFieldNames:\n",
      "            lst_myFieldNumbers.append(i)\n",
      "        i += 1\n",
      "     \n",
      "    for row in csvReader:\n",
      "        #lst_Row = [row[i] for i in lst_myFieldNumbers]\n",
      "        lst_Row = []\n",
      "        for i in lst_myFieldNumbers:\n",
      "            if len(row[i]) == 0:\n",
      "                lst_Row.append(np.nan)\n",
      "            else:\n",
      "                lst_Row.append(row[i])\n",
      "        lst_Rows.append(lst_Row)\n",
      "        rowCount += 1\n",
      "        if rowCount == maxReadRows:\n",
      "            break\n",
      "   \n",
      "df1 = pd.DataFrame(data = lst_Rows,\n",
      "                   columns = lst_myFieldNames,\n",
      "                   dtype = unicode)\n",
      "df1.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>ECP</th>\n",
        "      <th>Cell</th>\n",
        "      <th>Sector</th>\n",
        "      <th>Carrier</th>\n",
        "      <th>Date</th>\n",
        "      <th>Hour</th>\n",
        "      <th>Dropped Call Timestamp</th>\n",
        "      <th>Call Final Class qualifier</th>\n",
        "      <th>Secondary Call Final Class qualifier</th>\n",
        "      <th>Analysis Type</th>\n",
        "      <th>Analysis Reason</th>\n",
        "      <th>Mobile Vendor</th>\n",
        "      <th>Mobile serial number</th>\n",
        "      <th>Ending Band Class</th>\n",
        "      <th>Average FL Power (Watts)</th>\n",
        "      <th>Average RL RSSI rise (dB)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 01-25-2015</td>\n",
        "      <td> 8</td>\n",
        "      <td> 01/25/2015 08:40:39.000 AM</td>\n",
        "      <td> 100</td>\n",
        "      <td> 3</td>\n",
        "      <td> #TwoWay Alert#WeakActiveset Pilot##WeakActives...</td>\n",
        "      <td> #Twoway Alert: SourceId [3_614_1] Target Id-  ...</td>\n",
        "      <td> Reserved(x80)</td>\n",
        "      <td> 805CFF6A</td>\n",
        "      <td>     Unknown</td>\n",
        "      <td> 8</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 01-25-2015</td>\n",
        "      <td> 9</td>\n",
        "      <td> 01/25/2015 09:44:12.000 AM</td>\n",
        "      <td> 106</td>\n",
        "      <td> 2</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td>                                               NaN</td>\n",
        "      <td> Reserved(x80)</td>\n",
        "      <td> 8094E33E</td>\n",
        "      <td> PCS (2 GHz)</td>\n",
        "      <td> 6</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "  ECP Cell Sector Carrier        Date Hour      Dropped Call Timestamp  \\\n",
        "0   3    1      1       1  01-25-2015    8  01/25/2015 08:40:39.000 AM   \n",
        "1   3    1      1       1  01-25-2015    9  01/25/2015 09:44:12.000 AM   \n",
        "\n",
        "  Call Final Class qualifier Secondary Call Final Class qualifier  \\\n",
        "0                        100                                    3   \n",
        "1                        106                                    2   \n",
        "\n",
        "                                       Analysis Type  \\\n",
        "0  #TwoWay Alert#WeakActiveset Pilot##WeakActives...   \n",
        "1                                                NaN   \n",
        "\n",
        "                                     Analysis Reason  Mobile Vendor  \\\n",
        "0  #Twoway Alert: SourceId [3_614_1] Target Id-  ...  Reserved(x80)   \n",
        "1                                                NaN  Reserved(x80)   \n",
        "\n",
        "  Mobile serial number Ending Band Class Average FL Power (Watts)  \\\n",
        "0             805CFF6A           Unknown                        8   \n",
        "1             8094E33E       PCS (2 GHz)                        6   \n",
        "\n",
        "  Average RL RSSI rise (dB)  \n",
        "0                         0  \n",
        "1                         0  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(lst_Rows)\n",
      "check_drop(lst_Rows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use Pandas to read in data\n",
      "import pandas as pd\n",
      "import os\n",
      "import datetime\n",
      "import numpy as np\n",
      "from operator import itemgetter, attrgetter\n",
      "from StringIO import StringIO\n",
      "from pandas import *\n",
      "import matplotlib.pyplot as plt\n",
      "import csv\n",
      "from collections import Counter\n",
      "import itertools\n",
      "%pylab --no-import-all inline\n",
      "\n",
      "#note the given director is specific to the system where the data files are located.\n",
      "in_dir = r\"/vagrant/data_syndication/\"\n",
      "\n",
      "filename2 = 'Boston_CDMA.csv'\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# There are 4,727,508 records in the LA data file.\n",
      "# So we can use nrows and usecols to only grab the data we need.\n",
      "#Note I've opened the original file and attempted to select the columns of interest, but they may be off\n",
      "if True:\n",
      "    #use the pandas library\n",
      "    df3= pd.read_csv(filename2,skipinitialspace=True,dtype=unicode,  \\\n",
      "        usecols=[0,1,2,3,4,5,6,11,12,13,14,47,48, 59, 86, 87], nrows =900)\n",
      "    #df3= pd.read_csv(filename2,skipinitialspace=True,dtype=unicode, skiprows=range(2,800000), nrows=800000)\n",
      "    print  df3.info()\n",
      "    print df3.columns\n",
      "else:\n",
      "    a=[]\n",
      "    count = 0\n",
      "    csvreader = csv.DictReader(open(filename2,'rb'))\n",
      "    for row in csvreader:\n",
      "        a.append(row)\n",
      "        count = count + 1\n",
      "        if count == 500000:\n",
      "            break\n",
      "    print 'Finished reading ', type (a), len(a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#& dm['Call Final Class qualifier'] !=(101,102,109)\n",
      "# We first need to filter out the RFA/RFBs since they are not counted as dropped call\n",
      "# Adding sector to the groupby increases the count of things.\n",
      "df3 = df1.copy()\n",
      "df3 = df3.loc[(df3['Call Final Class qualifier'] !='109') & (df3['Call Final Class qualifier'] !='101')]\n",
      "print 'df3 is filtered ', df3.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now in a separate cell we compute the different groups using the filtered copy we made.\n",
      "if True:\n",
      "    #dm_sector = df3[['ECP', 'Cell','Sector']].groupby([df3['ECP'], df3['Cell'], df3['Sector']]).agg(len)\n",
      "    # dm_cell is still using the method that leaves a multi-level index\n",
      "    dm_cell = df3[['ECP', 'Cell']].groupby([df3['ECP'], df3['Cell']]).agg(len)\n",
      "    dm_cell.sort(columns='Cell',ascending =False,inplace = True)\n",
      "    #Here we use a method to unravel the multi-level index from the start.\n",
      "    dm = df3[['ECP', 'Cell','Sector','Carrier']].groupby(['ECP', 'Cell','Sector']).agg(len).reset_index()\n",
      "    dm.sort(columns = 'Carrier', ascending = False, inplace =True)\n",
      "    \n",
      "       \n",
      "    print '\\nWhat type is dm_sector now?   ', type(dm)\n",
      "    print '\\ndm_sector info \\n', dm.info()\n",
      "    #print '\\nNumber of items in dm_sector = ', len(dm)\n",
      "    print '\\nNeed to Keep the dm_cell structure to agg by cell Here is the info\\n', dm_cell.info()\n",
      "    print '\\n dm_cell first few records\\n', dm_cell.head(), '\\nNumber of items in dm_cell = ', len(dm_cell)\n",
      "     \n",
      "else:\n",
      "    dm = df2[['ECP', 'Cell','Call Final Class qualifier']].groupby([df2['ECP'], df2['Cell'],\\\n",
      "                                df2['Call Final Class qualifier']]).agg(len)\n",
      "    dm.sort(columns='Cell',ascending = False, inplace =True)\n",
      "    print 'df2 info this is unfiltered ', df2.info()\n",
      "    print '\\n\\nNow the grouped series dm ',dm.info()\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Computer the mean of the full monty (df2)\n",
      "#df2.describe()\n",
      " \n",
      "mean_count = dm_cell.values.mean()\n",
      "std_count = dm_cell.values.std()\n",
      "max_count = dm_cell.values.max()\n",
      "min_count = dm_cell.values.min()\n",
      "top_count = mean_count + std_count\n",
      " \n",
      "#Dropped Call Failure reason\n",
      "#Call Final Class qualifier\n",
      "\n",
      "print '\\nNumber of Cells in Filtered List = ', len(dm_cell),  \\\n",
      "'\\nNumber of cells in top offenders = ', len(dm_cell.loc[dm_cell['Cell']>top_count])\n",
      "# Find the cutoff statistics\n",
      "print '\\nMean =', mean_count, 'Standard deviation ',std_count, 'Mean + 1 sigma = ', mean_count+std_count\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create the statistics on a data set sorted also by sector.\n",
      "mean_count = dm['Carrier'].mean()\n",
      "std_count = dm['Carrier'].std()\n",
      "max_count = dm['Carrier'].max()\n",
      "min_count = dm['Carrier'].min()\n",
      "top_count_sector = mean_count + std_count\n",
      "sector_count = len(dm)\n",
      "bad_sectors = len(dm.loc[dm['Carrier']>top_count_sector])\n",
      "#Dropped Call Failure reason\n",
      "#Call Final Class qualifier\n",
      "\n",
      "print 'dm_sector Total Sector Count? ',len(dm),\\\n",
      "  \n",
      "print '\\nNumber of Sectors in top ', len(dm.loc[dm['Carrier']>top_count_sector])\n",
      "# Find the cutoff statistics\n",
      "print '\\nMean =', mean_count, 'Standard deviation ',std_count, 'Mean + 1 sigma = ', mean_count+std_count\n",
      "print '\\nMax = ', max_count, '\\nMin', min_count\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have to use dm (sector) with some other type of filter\n",
      "#Here we print out the top list of cells\n",
      "#This needs to be revised based on the new unpacked structure\n",
      "#dm3 = dm_cell.loc[dm_cell['Cell']>top_count]\n",
      "dm3 = dm.loc[dm['Carrier']>top_count_sector]\n",
      "#dm3 = dm2[['Cell','Sector', 'Carrier']].groupby([dm2['Cell'], dm2['Sector'], dm2['Carrier']]).agg(len)\n",
      "dm3.sort(columns='Carrier',ascending = False)\n",
      " \n",
      " \n",
      "print type(dm3), '\\nNumber of items', len(dm3), dm3.columns\n",
      " \n",
      "if True:\n",
      "    dm3.to_csv('output/top_cdma_drop_list-fullmarket.txt')\n",
      "    print \"Succcessfully write out \", len(dm3), ' items to top_cdma_drop_list-fullmarket-wk2.txt'\n",
      "\n",
      "#Let's attempt some clean up\n",
      "del dm3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " \n",
      "# Create a count summed by Drop Reason\n",
      "dm2 = df3.copy()\n",
      "dm3 = dm2[['Cell','Sector','Analysis Reason']].groupby([dm2['Cell'], dm2['Sector'],dm2['Analysis Reason']]).agg(len)\n",
      "print type(dm3), '\\nNumber of Sector', len(dm3)\n",
      "\n",
      "\n",
      "\n",
      "dm3.sort(columns='Cell',ascending = False)\n",
      "dm3\n",
      "#Print results if Data is correct\n",
      "if False:\n",
      "    dm3.to_csv('output/top_cdma_drop_reason.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_drop(arr):\n",
      "    ReasonCol = 9 \n",
      "    peg =peg2 = peg3 =0 \n",
      "    takestring =''\n",
      "    for row in range(len(arr)):\n",
      "        if arr[row][ReasonCol].find('#TwoWay') !=-1:\n",
      "            peg = peg + 1;takestring = arr[row][ReasonCol]\n",
      "        if arr[row][ReasonCol].find('#WeakActiveset') !=-1:\n",
      "            peg2 = peg2+1\n",
      "        if arr[row][ReasonCol].find('#Missing') !=-1:\n",
      "            peg3 = peg3 +1; takestring= arr[row][ReasonCol]\n",
      "\n",
      "    pctTwo = float(peg)/len(arr)\n",
      "    pctWeak = float(peg2)/len(arr)\n",
      "    pctMiss = float(peg3)/len(arr)\n",
      "    print 'Percent with TwoWay ', '%0.4f' % pctTwo, 'Total Number ',peg\n",
      "    print 'Percent with WeakActiveset ','%0.4f' % pctWeak, 'Total Number ',peg2\n",
      "    print 'Percent with Missing Neighbor ', '%0.4f' % pctMiss, 'Total Number ', peg3\n",
      "    print 'Total Peg count  not relevant', peg + peg2 + peg3\n",
      "    return\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_band(arr):\n",
      "    peg =peg2 = peg3 =0 \n",
      "    takestring =''\n",
      "    for row in range(len(arr)):\n",
      "        if arr[row][59].find('CDMA') !=-1:\n",
      "            peg = peg + 1;takestring = arr[row][13]\n",
      "        if arr[row][59].find('PCS') !=-1:\n",
      "            peg2 = peg2+1\n",
      "        if arr[row][59].find('Unknown') !=-1:\n",
      "            peg3 = peg3 +1; takestring= arr[row][13]\n",
      "\n",
      "    pctCDMA = float(peg)/len(arr)\n",
      "    pctPCS = float(peg2)/len(arr)\n",
      "    pctUnk = float(peg3)/len(arr)\n",
      "    print 'Percent with CDMA ', '%0.4f' % pctCDMA, 'Total Number ',peg\n",
      "    print 'Percent with PCS ','%0.4f' % pctPCS, 'Total Number ',peg2\n",
      "    print 'Percent with Unknown ', '%0.4f' % pctUnk, 'Total Number ', peg3\n",
      "    print 'Total Peg count  not relevant', peg + peg2 + peg3\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check Ending Band from full data set.\n",
      "if False:\n",
      "    check_band(arr3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use the Check drop routine on the larger array to get statistics\n",
      "# Note arr3 equal full data set\n",
      "if False:\n",
      "    check_drop(arr3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now let's try to manipulate the impact of the drops by reducing the top offenders number of drops = mean.\n",
      "# Recall that dm - is the sector drop count.  dm_cell is the cell drop count\n",
      "# dm3 is a free variable.\n",
      "# from above we already know how select only the rows above our standard deviation. let's try to set them all to top_sector.\n",
      "dm3 = dm.copy()\n",
      "dm4 = dm.copy()\n",
      "# This will set the number of drops to the mean for the sector\n",
      "dm3 = dm.loc[dm['Carrier'] > top_count_sector]\n",
      "dm3.Carrier = int(top_count_sector)\n",
      "dm4 = dm.loc[dm['Carrier']<=top_count_sector]\n",
      "\n",
      "print 'Total number of sectors = ',sector_count, '\\n Above Normal ', bad_sectors\n",
      "print 'Now the non top sectors ',  len(dm4)\n",
      "print '\\nJust Checking ', len(dm4) + bad_sectors\n",
      "\n",
      "#print dm3.head(), '\\n\\nOk now original \\n',dm.head(), '\\nTop Count ', top_count_sector\n",
      "# Now let's put them back together and recompute the difference in number of drops!!\n",
      "dm2 = concat([dm3,dm4])\n",
      "print 'dm2 info\\n', dm2.info(), '\\n\\n','Describing dm\\n', dm.describe(),  '\\n Now the reimagined one \\n',dm2.describe()\n",
      "del dm3\n",
      "del dm4\n",
      "del dm2\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's see how to manipulate the dF now\n",
      "print df3.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def norm_cdf(mean=0.0, std=1.0, min=0, max=500):\n",
      "    import scipy as sp\n",
      "    from scipy import stats\n",
      "    # 50 numbers between -3\u03c3 and 3\u03c3\n",
      "    #x = sp.linspace(-3*std, 3*std, 50)\n",
      "    x = sp.linspace(min, max, 50)\n",
      "    # CDF at these values\n",
      "    y = stats.norm.cdf(x, loc=mean, scale=std)\n",
      "\n",
      "    plt.plot(x,y, color=\"black\")\n",
      "    plt.xlabel(\"Variate\")\n",
      "    plt.ylabel(\"Cumulative Probability\")\n",
      "    plt.title(\"CDF for Gaussian of mean = {0} & std. deviation = {1}\".format(\n",
      "               mean, std))\n",
      "    plt.draw()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig =plt.figure()\n",
      "plt.clf()\n",
      "bin_tick =np.arange(top_count_sector,max_count,50, dtype=int)\n",
      "\n",
      "#dm2.hist()\n",
      "#dm2.plot(x=['ECP','Cell'], y ='Carrier',kind='line')\n",
      "#dm.plot(x=['ECP','Cell'], y='Carrier' )\n",
      "#plt.subplots(2,2)\n",
      "ax1 = fig.add_subplot(2,2,1)\n",
      " \n",
      "_ = ax1.plot(dm['Carrier'].values, drawstyle='steps-post', label ='steps-post')\n",
      "ax2 = fig.add_subplot(2,2,3)\n",
      "\n",
      "bin_tick = np.arange(min_count,max_count,50, dtype=int)\n",
      "\n",
      "_ = ax2.hist(dm['Carrier'],bins=bin_tick)\n",
      "ax3 = fig.add_subplot(2,2,4)\n",
      "norm_cdf(68, std_count, min_count, max_count)\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Unless we got sloppy, dm2 should still be only the Top offenders. so we want to also group by sector and carrier\n",
      "#This seems to be wrong output in the columns\n",
      "#ingore the fact that the last 4 columns all equal the same amount becasue we counting drops at this point.\n",
      "# What seems wrong is the sector/carrier columns.  Those are data/hour so the file is off by a column somewhere.\n",
      "\n",
      "dm2 =df3.copy()\n",
      "dm3 = dm2[['ECP','Cell','Sector', 'Carrier']].groupby([dm2['ECP'], dm2['Cell'], dm2['Sector'], dm2['Carrier']]).agg(len)\n",
      "print type(dm3), '\\nNumber of Sector', len(dm3)\n",
      "if True:\n",
      "    dm3.to_csv('output/top_cdma_drop_list.csv')\n",
      "\n",
      "dm3.sort(columns='ECP',ascending = False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('display.width', 100,'display.column_space', 25)\n",
      "print  df3.describe(), df3.shape, 1776+1299*2\n",
      "cap =[]\n",
      "cap = df3.describe()\n",
      "if False:\n",
      "    cap.to_csv('output/top_describe.txt')\n",
      "%pylab --no-import-all inline\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " \n",
      "# Create a count to look for the cells with the most drops\n",
      "#this is obvsioulsy broken.  Likely dm2 is not the right starting point to sort.\n",
      "#Same as above I seem to be off by a column somewhere.\n",
      "dm3 = df3[['Cell','Sector','Ending Band Class']].groupby([df3['Cell'], df3['Sector'],df3['Ending Band Class']]).agg(len)\n",
      " \n",
      "print type(dm3), '\\nEnding Band Class', len(dm3)\n",
      "\n",
      "dm3.sort(columns='Cell',ascending = False)\n",
      "if False:\n",
      "    dm3.to_csv('output/top_cdma_drop_BC.txt')\n",
      "dm3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dm3 = df3[['Cell','Sector', 'Carrier','Average RL RSSI rise (dB)']].groupby([df3['Cell'], \\\n",
      "                         df3['Sector'], df3['Carrier'], df3['Average RL RSSI rise (dB)']]).agg(len)\n",
      "print type(dm3), '\\nNumber of Sector', len(dm3)\n",
      "if False:\n",
      "    dm3.to_csv('output/top_cdma_drop_RSSI.txt')\n",
      "dm3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "dm3 = df3[['Cell','Sector', 'Carrier','Analysis Type']].groupby([df3['Cell'], \\\n",
      "                         df3['Sector'], df3['Carrier'], df3['Analysis Type']]).agg(len)\n",
      "dm3 = df3[['Cell','Sector', 'Carrier','Analysis Type']].groupby([df3['Analysis Type']]).agg(len)\n",
      "print  '\\nNumber of Sector', len(dm3)\n",
      "dm3.sort(columns='Analysis Type',ascending = False)\n",
      "if False:\n",
      "    dm3.to_csv('output/top_cdma_drop_Reason.txt')\n",
      "dm3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}